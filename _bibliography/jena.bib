@article{vojir2023calibrated,
  title={Calibrated Out-of-Distribution Detection with a Generic Representation},
  author={Vojir, Tomas and Sochman, Jan and Aljundi, Rahaf and Matas, Jiri},
  journal={arXiv preprint arXiv:2303.13148},
  year={2023},
  arxiv={2303.13148},
  doi={10.48550/arXiv.2303.13148},
  bibtex_show={},
  code={https://github.com/vojirt/GROOD},
  abstract={Out-of-distribution detection is a common issue in deploying vision models in practice and solving it is an essential building block in safety critical applications. Existing OOD detection solutions focus on improving the OOD robustness of a classification model trained exclusively on in-distribution (ID) data. In this work, we take a different approach and propose to leverage generic pre-trained representations. We first investigate the behaviour of simple classifiers built on top of such representations and show striking performance gains compared to the ID trained representations. We propose a novel OOD method, called GROOD, that achieves excellent performance, predicated by the use of a good generic representation. Only a trivial training process is required for adapting GROOD to a particular problem. The method is simple, general, efficient, calibrated and with only a few hyper-parameters. The method achieves state-of-the-art performance on a number of OOD benchmarks, reaching near perfect performance on several of them. The source code is available at this https URL.}
}

@InProceedings{Neoral2021,
    author    = {Neoral, Michal and {\v{S}}ochman, Jan and Matas, Ji{\v{r}}{\'i}},
    title     = {Monocular Arbitrary Moving Object Discovery and Segmentation},
    booktitle = {The 32nd British Machine Vision Conference -- BMVC 2021},
    year      = {2021},
    pdf       = {https://www.bmvc2021-virtualconference.com/assets/papers/1500.pdf},
    code      = {https://github.com/michalneoral/Raptor},
    bibtex_show={},
    abstract  = {We propose a method for discovery and segmentation of objects that are, or their parts are, independently moving in the scene. Given three monocular video frames, the method outputs semantically meaningful regions, i.e. regions corresponding to the whole object, even when only a part of it moves.
The architecture of the CNN-based end-to-end method, called Raptor, combines semantic and motion backbones, which pass their outputs to a final region segmentation network. The semantic backbone is trained in a class-agnostic manner in order to generalise to object classes beyond the training data. The core of the motion branch is a geometrical cost volume computed from optical flow, optical expansion, mono-depth and the estimated camera motion.
Evaluation of the proposed architecture on the instance motion segmentation and binary moving-static segmentation problems on KITTI, DAVIS-Moving and YTVOS-Moving datasets shows that the proposed method achieves state-of-the-art results on all the datasets and is able to generalise well to various environments. For the KITTI dataset, we provide an upgraded instance motion segmentation annotation which covers all moving objects. Dataset, code and models are available on the github project page github.com/michalneoral/Raptor.}
    }

@InProceedings{Neoral2018,
  author    = {Michal Neoral and Jan {\v S}ochman and Jiri Matas},
  title     = {Continual Occlusions and Optical Flow Estimation},
  booktitle={Asian Conference on Computer Vision},
  pdf       = {https://link.springer.com/content/pdf/10.1007/978-3-030-20870-7_10.pdf},
  pages={159--174},
  arxiv     = {1811.01602},
  bibtex_show = {},
  year      = {2018},
  organization={Springer},
  abstract  = {Two optical flow estimation problems are addressed: (i)
occlusion estimation and handling, and (ii) estimation from image
sequences longer than two frames. The proposed ContinualFlow method
estimates occlusions before flow, avoiding the use of flow corrupted by
occlusions for their estimation. We show that providing occlusion masks
as an additional input to flow estimation improves the standard performance metric by more than 25\% on both KITTI and Sintel. As a
second contribution, a novel method for incorporating information from
past frames into flow estimation is introduced. The previous frame flow
serves as an input to occlusion estimation and as a prior in occluded
regions, i.e. those without visual correspondences. By continually using
the previous frame flow, ContinualFlow performance improves further by
18\% on KITTI and 7\% on Sintel, achieving top performance on KITTI
and Sintel.}
}

@InProceedings{Neoral2017,
  author    = {Michal Neoral and Jan Sochman},
  title     = {Object Scene Flow with Temporal Consistency},
  booktitle = {22nd Computer Vision Winter Workshop},
  pdf       = {neoral_cvww2017.pdf},
  abstract  = {In this paper, we propose several improvements of the Object Scene Flow (OSF) algorithm [14]. The OSF does not use the scene flow
estimated in previous frame nor the object labels and
their corresponding object motion information. The
goal of this paper is to use this information in order
to produce temporarily consistent output throughout
the whole video sequence. We evaluate the progress
on the KITTI’15 multiframe dataset. We show that
propagating the labels and the corresponding motion information using the estimated flow reduces the
false negative rate (missed cars). Together with two
further proposed improvements the overall reduction
of false negative is 42\%. The proposed improvements
also reduce EPE on the KITTI’15 scene flow from
10.63\% to 9.65\%.},
  bibtex_show = {},
  year      = {2017}
}

@article{Ferryman2013789,
title = "Robust abandoned object detection integrating wide area visual surveillance and social context",
journal = "Pattern Recognition Letters",
volume = "34",
number = "7",
pages = "789 - 798",
year = "2013",
note = "<ce:title>Scene Understanding and Behaviour Analysis</ce:title>",
issn = "0167-8655",
doi = "10.1016/j.patrec.2013.01.018",
url = "http://www.sciencedirect.com/science/article/pii/S0167865513000226",
author = "James Ferryman and David Hogg and Jan Sochman and Ardhendu Behera and José A. Rodriguez-Serrano and Simon Worgan and Longzhen Li and Valerie Leung and Murray Evans and Philippe Cornic and Stéphane Herbin and Stefan Schlenger and Michael Dose",
keywords = "Wide area video surveillance",
keywords = "Behaviour analysis",
keywords = "Abandoned objects",
abstract = "This paper presents a video surveillance framework that robustly and efficiently detects abandoned objects in surveillance scenes. The framework is based on a novel threat assessment algorithm which combines the concept of ownership with automatic understanding of social relations in order to infer abandonment of objects. Implementation is achieved through development of a logic-based inference engine based on Prolog. Threat detection performance is conducted by testing against a range of datasets describing realistic situations and demonstrates a reduction in the number of false alarms generated. The proposed system represents the approach employed in the EU SUBITO project (Surveillance of Unattended Baggage and the Identification and Tracking of the Owner).",
bibtex_show = {},
pdf = {ferryman-prl2013.pdf},
}

@INPROCEEDINGS{Sochman-accv2007,
  author = {{\v S}ochman, Jan and Matas, Ji{\v r}{\' \i}},
  title = {Learning A Fast Emulator of a Binary Decision Process},
  booktitle = {ACCV},
  year = {2007},
  editor = {Yasushi Yagi and Sing Bing Kang and In So Kweon and Hongbin Zha},
  volume = {II},
  pages = {236--245},
  address = {Berlin Heidelberg},
  publisher = {Springer},
  series = {LNSC},
  isbn = {978-3-540-76389-5},
  doi = {10.1007/978-3-540-76390-1_24},
  abstract = {Computation time is an important performance characteristic of computer
	vision algorithms. This paper shows how existing (slow) binary-valued
	decision algorithms can be approximated by a trained WaldBoost classifier,
	which minimises the decision time while guaranteeing predefined approximation
	precision. The core idea is to take an existing algorithm as a black
	box performing some useful binary decision task and to train the
	WaldBoost classifier as its emulator.
	
	
	 Two interest point detectors, Hessian-Laplace and Kadir-Brady saliency
	detector, are emulated to demonstrate the approach. The experiments
	show similar repeatability and matching score of the original and
	emulated algorithms while achieving a 70-fold speed-up for Kadir-Brady
	detector.},
  bibtex_show = {},
  pdf = {sochman-accv2007.pdf}
}

@InProceedings{Sochman-AFGR:2004,
  author =      {{\v S}ochman, Jan and Matas, Ji{\v r}{\'\i}},
  title =       {{AdaBoost} with Totally Corrective Updates for Fast 
                 Face Detection},
  year =        {2004},
  pages =       {445--450},
  booktitle =   {FGR '04: Proceeding of the Sixth IEEE International
                 Conference on Automatic Face and Gesture Recognition},
  editor =      {Deeber Azada},
  publisher =   {IEEE Computer Society},
  address =     {10662 Los Vaqueros Circle, P.O.Box 3014, Los Alamitos, USA},
  isbn =        {0-7695-2122-3},
  book_pages =  {904},
  month =       {May},
  day =         {17--19},
  venue =       {Center for Artificial Vision Research, 
                 Korea University, Jamsil Hotel, Seoul, Korea South},
  organization ={IEEE Computer Society; Korea Information Science
    Society; Korea Science and Engineering Foundation; Ministry of
    Information and Communication, Korea; US Air Force Office of
    Scientific Research; WatchVision, Inc.},
  annote = {An extension of the AdaBoost learning algorithm is
    proposed and brought to bear on the face detection problem. In
    each weak classifier selection cycle, the novel totally corrective
    algorithm reduces aggressively the upper bound on the training
    error by correcting coefficients of all weak classifiers. The
    correction steps are proven to lower the upper bound on the error
    without increasing computational complexity of the resulting
    detector. We show experimentally that for the face detection
    problem, where large training sets are available, the technique
    does not overfit.
      A cascaded face detector of the Viola-Jones type is built using
    AdaBoost with the Totally Corrective Update. The same detection
    and false positive rates are achieved with a detector that is
    20 perc. faster and consists of only a quarter of the weak
    classifiers needed for a classifier trained by standard
    AdaBoost. The latter property facilitates hardware implementation,
    the former opens scope for the increase in the search space,
    e.g. the range of scales at which faces are sought.},
  keywords =    {AdaBoost, face detection, computer vision},
}

@InProceedings{sochman-waldboost-cvpr05,
author =      {{\v S}ochman, Jan and Matas, Ji{\v r}{\' \i}},
title =       {WaldBoost  - Learning for Time Constrained Sequential Detection},
booktitle =   {Proc. of Conference on Computer Vision and Pattern Recognition (CVPR)},
address =     {Los Alamitos, USA} ,
year =        {2005},
month =       {June},
day =         {20--25},
isbn        = {0-7695-2372-2},
publisher   = {IEEE Computer Society},
book_pages  = {1219},
pages    =    {150--157},
doi={10.1109/CVPR.2005.373},
annote = { In many computer vision classification problems, both the
  error and time characterizes the quality of a decision. We show that
  such problems can be formalized in the framework of sequential
  decision-making. If the false positive and false negative error
  rates are given, the optimal strategy in terms of the shortest
  average time to decision (number of measurements used) is the Wald's
  sequential probability ratio test (SPRT).  We built on the optimal
  SPRT test and enlarge its capabilities to problems with dependent
  measurements. We show, how the limitations of SPRT to a priori
  ordered measurements and known joint probability density functions
  can be overcome. We propose an algorithm with near optimal time -
  error rate trade-off, called WaldBoost, which integrates the
  AdaBoost algorithm for measurement selection and ordering and the
  joint probability density estimation with the optimal SPRT decision
  strategy.  The WaldBoost algorithm is tested on the face detection
  problem. The results are superior to the state-of-the-art methods in
  average evaluation time and comparable in detection rates.  },
keywords =    {Adaboost, cascade, Wald's SPRT, sequential analysis, face detection},
editor      = {Schmid, Cordelia and Soatto, Stefano and Tomasi, Carlo},
venue       = {San Diego, California, USA  },
volume      = { 2 },
bibtex_show = {},
pdf = {sochman-waldboost-cvpr05.pdf},
preview={wb.jpg}
}

@inproceedings{Terzic2010,
  author    = {Kasim Terzic and Lothar Hotz and Jan Sochman},
  title     = {Interpreting Structures in Man-made Scenes - Combining Low-Level and High-Level Structure Sources},
  year      = {2010},
  pages     = {357--364},
  bibtex_show = {},
  pdf = {Terzic2010.pdf},
  booktitle={Proceedings of the 2nd International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  publisher={SciTePress},
  organization={INSTICC},
  doi={10.5220/0002735303570364},
  isbn={978-989-674-021-4},
  issn={2184-433X},
}

@InProceedings{Sochman-ICPR-2004,
  author =      {{\v S}ochman, Jan and Matas, Ji{\v r}{\'\i}},
  title =       {Inter-stage Feature Propagation in Cascade Building with {AdaBoost}},
  year =        {2004},
  pages =       {236--239},
  booktitle =   {Proceedings of ICPR 2004 17th International Conference on
                 Pattern Recognition},
  editor =      {Josef Kittler, Maria Petrou, Mark Nixon},
  publisher =   {IEEE Computer Society},
  address =     {10662 Los Vaqueros Circle, P.O.Box 3014, Los Alamitos, USA},
  isbn =        {0-7695-2128-2},
  volume =      {1},
  book_pages =  {840},
  month =       {August},
  day =         {23--26},
  venue =       {IAPR, Cambridge, UK},
  organization ={IEEE},
  annote = {A modification of the cascaded detector with the AdaBoost
    trained stage classifiers is proposed and brought to bear on the
    face detection problem. The cascaded detector is a sequential
    classifier with the ability of early rejection of easy
    samples. Each decision in the sequence is made by a separately
    trained classifier, a stage classifier. In proposed modification
    the features from one stage of training are propagated to the next
    stage classifier.  The proposed intra-stage feature propagation is
    shown to be greedily optimal, does not increase computational
    complexity of the stage classifier and leads to shorter stage
    classifiers and accordingly to faster detectors.
  
    A cascaded face detector is built with the intra-stage feature
    propagation and is compared with the Viola and Jones approach. The
    same detection and false positive rates are achieved with a
    detector that is 25 perc. faster and consists of only two thirds of
    the weak classifiers needed for a cascade trained by the Viola and
    Jones approach. The latter property facilitates hardware
    implementation, the former opens scope for the increase in the
    search space, e.g. the range of scales at which faces are
    sought.},
  keywords =    {AdaBoost, face detection, computer vision},
}

@INPROCEEDINGS{Grabner2008,
  author = {Grabner, H. and {\v S}ochman, J. and Bischof, H. and Matas, J.},
  title = {Training Sequential On-line Boosting Classifier for Visual Tracking},
  booktitle = {19th International Conference on Pattern Recognition},
  year = {2008},
  abstract = {On-line boosting allows to adapt a trained classifier
to changing environmental conditions or to use sequentially
available training data. Yet, two important problems
in the on-line boosting training remain unsolved:
(i) classifier evaluation speed optimization and, (ii) automatic
classifier complexity estimation. In this paper
we show how the on-line boosting can be combined with
Wald's sequential decision theory to solve both of the
problems.

The properties of the proposed on-line WaldBoost algorithm
are demonstrated on a visual tracking problem.
The complexity of the classifier is changing dynamically
depending on the difficulty of the problem. On average,
a speedup of a factor of 5-10 is achieved compared to
the non-sequential on-line boosting.},
  doi={10.1109/ICPR.2008.4761678},
  bibtex_show={},
  pdf={Sochman-icpr2008.pdf}
}

@ARTICLE{Sochman2009,
  author = {Jan {\v S}ochman and Ji{\v r}{\'\i} Matas},
  title = {Learning Fast Emulators of Binary Decision Processes},
  journal = {International Journal of Computer Vision},
  year = {2009},
  volume = {83},
  pages = {149--163},
  number = {2},
  month = {June},
  abstract = {Computation time is an important performance characteristic of computer
	vision algorithms. The paper shows how existing (slow) binary decision
	algorithms can be approximated by a (fast) trained WaldBoost classifier.
	WaldBoost learning minimises the decision time of the classifier
	while guaranteeing predefined precision. We show that the WaldBoost
	algorithm together with bootstrapping is able to efficiently handle
	an effectively unlimited number of training examples provided by
	the implementation of the approximated algorithm.
	
	
	Two interest point detectors, the Hessian-Laplace and the Kadir-Brady
	saliency detectors, are emulated to demonstrate the approach. Experiments
	show that while the repeatability and matching scores are similar
	for the original and emulated algorithms, a 9-fold speed-up for
	the Hessian-Laplace detector and a 142-fold speed-up for the Kadir-Brady
	detector is achieved. For the Hessian-Laplace detector, the achieved
	speed is similar to SURF, a popular and very fast handcrafted modification
	of Hessian-Laplace; the WaldBoost emulator approximates the output
	of the Hessian-Laplace detector more precisely.},
  doi = {10.1007/s11263-009-0229-x},
  keywords = {Boosting, AdaBoost, Sequential probability ratio test, Sequential
	decision making, WaldBoost, Interest point detectors, Machine learning},
  bibtex_show = {},
  pdf = {sochman-ijcv09.pdf},
}
