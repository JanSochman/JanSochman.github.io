<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>publications | Jan  Šochman</title>
    <meta name="author" content="Jan  Šochman">
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://jansochman.github.io/publications/">

    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jan </span>Šochman</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/misc/">misc</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<p>Selection of my favourite publications. A full list can be found at my <a href="https://scholar.google.com/citations?user=gJlLSIEAAAAJ" rel="external nofollow noopener" target="_blank">scholar profile</a>.</p>

<div class="publications">
  <h2 class="year">2024</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="bravo2024" class="col-sm-8">
        <!-- Title -->
        <div class="title">The BRAVO Semantic Segmentation Challenge Results in UNCV2024</div>
        <!-- Author -->
        <div class="author">
        

        Tuan-Hung Vu, Eduardo Valle, Andrei Bursuc, Tommie Kerssies, and
          <span class="more-authors" title="click to view 15 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '15 more authors' ? 'Daan Geus, Gijs Dubbelman, Long Qian, Bingke Zhu, Yingying Chen, Ming Tang, Jinqiao Wang, Tomáš Vojíř, Jan Šochman, Jiří Matas, Michael Smith, Frank Ferrie, Shamik Basu, Christos Sakaridis, Luc Van Gool' : '15 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">15 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://arxiv.org/abs/2409.15107" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2409.15107"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/pixood-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/pixood-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/pixood-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/pixood.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="pixood.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="vojir2024pixood" class="col-sm-8">
        <!-- Title -->
        <div class="title">PixOOD: Pixel-Level Out-of-Distribution Detection</div>
        <!-- Author -->
        <div class="author">
        

        Tomáš Vojı́ř, <em>Jan Šochman</em>, and Jiřı́ Matas</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2405.19882" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07720.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07720-supp.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a>
            <a href="https://github.com/vojirt/PixOOD" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2405.19882"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We propose a dense image prediction out-of-distribution detection algorithm, called PixOOD, which does not require training on samples of anomalous data and is not designed for a specific application which avoids traditional training biases. In order to model the complex intra-class variability of the in-distribution data at the pixel level, we propose an online data condensation algorithm which is more robust than standard K-means and is easily trainable through SGD. We evaluate PixOOD on a wide range of problems. It achieved state-of-the-art results on four out of seven datasets, while being competitive on the rest.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">vojir2024pixood</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PixOOD: Pixel-Level Out-of-Distribution Detection}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Voj{\'\i}\v{r}, Tom\'a\v{s} and \v{S}ochman, Jan and Matas, Ji\v{r}{\'\i}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Computer Vision – ECCV 2024}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2405.19882}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CV}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/grood-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/grood-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/grood-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/grood.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="grood.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="vojir2023calibrated" class="col-sm-8">
        <!-- Title -->
        <div class="title">Calibrated Out-of-Distribution Detection with a Generic Representation</div>
        <!-- Author -->
        <div class="author">
        

        Tomáš Vojı́ř, <em>Jan Šochman</em>, Rahaf Aljundi, and Jiřı́ Matas</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops</em>, Oct 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2303.13148" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://openaccess.thecvf.com/content/ICCV2023W/UnCV/papers/Vojir_Calibrated_Out-of-Distribution_Detection_with_a_Generic_Representation_ICCVW_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://openaccess.thecvf.com/content/ICCV2023W/UnCV/supplemental/Vojir_Calibrated_Out-of-Distribution_Detection_ICCVW_2023_supplemental.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a>
            <a href="https://github.com/vojirt/GROOD" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1109/ICCVW60793.2023.00485"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1109/ICCVW60793.2023.00485" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Out-of-distribution detection is a common issue in deploying vision models in practice and solving it is an essential building block in safety critical applications. Existing OOD detection solutions focus on improving the OOD robustness of a classification model trained exclusively on in-distribution (ID) data. In this work, we take a different approach and propose to leverage generic pre-trained representations. We first investigate the behaviour of simple classifiers built on top of such representations and show striking performance gains compared to the ID trained representations. We propose a novel OOD method, called GROOD, that achieves excellent performance, predicated by the use of a good generic representation. Only a trivial training process is required for adapting GROOD to a particular problem. The method is simple, general, efficient, calibrated and with only a few hyper-parameters. The method achieves state-of-the-art performance on a number of OOD benchmarks, reaching near perfect performance on several of them. The source code is available at this https URL.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">vojir2023calibrated</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Voj{\'\i}\v{r}, Tom\'a\v{s} and \v{S}ochman, Jan and Aljundi, Rahaf and Matas, Ji\v{r}{\'\i}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Calibrated Out-of-Distribution Detection with a Generic Representation}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4507-4516}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICCVW60793.2023.00485}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/raptor-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/raptor-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/raptor-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/raptor.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="raptor.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="Neoral2021" class="col-sm-8">
        <!-- Title -->
        <div class="title">Monocular Arbitrary Moving Object Discovery and Segmentation</div>
        <!-- Author -->
        <div class="author">
        

        Michal Neoral, <em>Jan Šochman</em>, and Jiří Matas</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In The 32nd British Machine Vision Conference – BMVC 2021</em>, Oct 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.bmvc2021-virtualconference.com/assets/papers/1500.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/michalneoral/Raptor" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We propose a method for discovery and segmentation of objects that are, or their parts are, independently moving in the scene. Given three monocular video frames, the method outputs semantically meaningful regions, i.e. regions corresponding to the whole object, even when only a part of it moves.
The architecture of the CNN-based end-to-end method, called Raptor, combines semantic and motion backbones, which pass their outputs to a final region segmentation network. The semantic backbone is trained in a class-agnostic manner in order to generalise to object classes beyond the training data. The core of the motion branch is a geometrical cost volume computed from optical flow, optical expansion, mono-depth and the estimated camera motion.
Evaluation of the proposed architecture on the instance motion segmentation and binary moving-static segmentation problems on KITTI, DAVIS-Moving and YTVOS-Moving datasets shows that the proposed method achieves state-of-the-art results on all the datasets and is able to generalise well to various environments. For the KITTI dataset, we provide an upgraded instance motion segmentation annotation which covers all moving objects. Dataset, code and models are available on the github project page github.com/michalneoral/Raptor.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Neoral2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Neoral, Michal and {\v{S}}ochman, Jan and Matas, Ji{\v{r}}{\'i}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Monocular Arbitrary Moving Object Discovery and Segmentation}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The 32nd British Machine Vision Conference -- BMVC 2021}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/contflow-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/contflow-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/contflow-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/contflow.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="contflow.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="Neoral2018" class="col-sm-8">
        <!-- Title -->
        <div class="title">Continual Occlusions and Optical Flow Estimation</div>
        <!-- Author -->
        <div class="author">
        

        Michal Neoral, <em>Jan Šochman</em>, and Jiri Matas</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Asian Conference on Computer Vision</em>, Oct 2018
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/1811.01602" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://link.springer.com/content/pdf/10.1007/978-3-030-20870-7_10.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1007/978-3-030-20870-7_10"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-030-20870-7_10" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Two optical flow estimation problems are addressed: (i)
occlusion estimation and handling, and (ii) estimation from image
sequences longer than two frames. The proposed ContinualFlow method
estimates occlusions before flow, avoiding the use of flow corrupted by
occlusions for their estimation. We show that providing occlusion masks
as an additional input to flow estimation improves the standard performance metric by more than 25% on both KITTI and Sintel. As a
second contribution, a novel method for incorporating information from
past frames into flow estimation is introduced. The previous frame flow
serves as an input to occlusion estimation and as a prior in occluded
regions, i.e. those without visual correspondences. By continually using
the previous frame flow, ContinualFlow performance improves further by
18% on KITTI and 7% on Sintel, achieving top performance on KITTI
and Sintel.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Neoral2018</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Neoral, Michal and {\v S}ochman, Jan and Matas, Jiri}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Continual Occlusions and Optical Flow Estimation}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Asian Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{159--174}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-20870-7_10}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2013</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/social-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/social-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/social-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/social.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="social.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="Ferryman2013789" class="col-sm-8">
        <!-- Title -->
        <div class="title">Robust abandoned object detection integrating wide area visual surveillance and social context</div>
        <!-- Author -->
        <div class="author">
        

        James Ferryman, David Hogg, <em>Jan Sochman</em>, Ardhendu Behera, and
          <span class="more-authors" title="click to view 9 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '9 more authors' ? 'José A. Rodriguez-Serrano, Simon Worgan, Longzhen Li, Valerie Leung, Murray Evans, Philippe Cornic, Stéphane Herbin, Stefan Schlenger, Michael Dose' : '9 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">9 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Pattern Recognition Letters</em>, Oct 2013
        </div>
        <div class="periodical">
          <ce:title>Scene Understanding and Behaviour Analysis</ce:title>
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/ferryman-prl2013.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1016/j.patrec.2013.01.018"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1016/j.patrec.2013.01.018" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper presents a video surveillance framework that robustly and efficiently detects abandoned objects in surveillance scenes. The framework is based on a novel threat assessment algorithm which combines the concept of ownership with automatic understanding of social relations in order to infer abandonment of objects. Implementation is achieved through development of a logic-based inference engine based on Prolog. Threat detection performance is conducted by testing against a range of datasets describing realistic situations and demonstrates a reduction in the number of false alarms generated. The proposed system represents the approach employed in the EU SUBITO project (Surveillance of Unattended Baggage and the Identification and Tracking of the Owner).</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Ferryman2013789</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robust abandoned object detection integrating wide area visual surveillance and social context}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Pattern Recognition Letters}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{789 - 798}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{&lt;ce:title&gt;Scene Understanding and Behaviour Analysis&lt;/ce:title&gt;}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0167-8655}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.patrec.2013.01.018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.sciencedirect.com/science/article/pii/S0167865513000226}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ferryman, James and Hogg, David and Sochman, Jan and Behera, Ardhendu and Rodriguez-Serrano, José A. and Worgan, Simon and Li, Longzhen and Leung, Valerie and Evans, Murray and Cornic, Philippe and Herbin, Stéphane and Schlenger, Stefan and Dose, Michael}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Abandoned objects}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2010</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/structures-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/structures-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/structures-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/structures.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="structures.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="Terzic2010" class="col-sm-8">
        <!-- Title -->
        <div class="title">Interpreting Structures in Man-made Scenes - Combining Low-Level and High-Level Structure Sources</div>
        <!-- Author -->
        <div class="author">
        

        Kasim Terzic, Lothar Hotz, and <em>Jan Sochman</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the 2nd International Conference on Agents and Artificial Intelligence - Volume 1: ICAART</em>, Oct 2010
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/Terzic2010.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.5220/0002735303570364"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.5220/0002735303570364" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Terzic2010</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Terzic, Kasim and Hotz, Lothar and Sochman, Jan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Interpreting Structures in Man-made Scenes - Combining Low-Level and High-Level Structure Sources}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2010}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{357--364}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2nd International Conference on Agents and Artificial Intelligence - Volume 1: ICAART}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{SciTePress}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{INSTICC}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5220/0002735303570364}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-989-674-021-4}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2184-433X}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2009</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/emulator_ijcv-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/emulator_ijcv-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/emulator_ijcv-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/emulator_ijcv.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="emulator_ijcv.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="Sochman2009" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning Fast Emulators of Binary Decision Processes</div>
        <!-- Author -->
        <div class="author">
        

        <em>Jan Šochman</em>, and Jiřı́ Matas</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>International Journal of Computer Vision</em>, Jun 2009
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/sochman-ijcv09.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1007/s11263-009-0229-x"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1007/s11263-009-0229-x" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Computation time is an important performance characteristic of computer
	vision algorithms. The paper shows how existing (slow) binary decision
	algorithms can be approximated by a (fast) trained WaldBoost classifier.
	WaldBoost learning minimises the decision time of the classifier
	while guaranteeing predefined precision. We show that the WaldBoost
	algorithm together with bootstrapping is able to efficiently handle
	an effectively unlimited number of training examples provided by
	the implementation of the approximated algorithm.
	
	
	Two interest point detectors, the Hessian-Laplace and the Kadir-Brady
	saliency detectors, are emulated to demonstrate the approach. Experiments
	show that while the repeatability and matching scores are similar
	for the original and emulated algorithms, a 9-fold speed-up for
	the Hessian-Laplace detector and a 142-fold speed-up for the Kadir-Brady
	detector is achieved. For the Hessian-Laplace detector, the achieved
	speed is similar to SURF, a popular and very fast handcrafted modification
	of Hessian-Laplace; the WaldBoost emulator approximates the output
	of the Hessian-Laplace detector more precisely.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Sochman2009</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{{\v S}ochman, Jan and Matas, Ji{\v r}{\'\i}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Fast Emulators of Binary Decision Processes}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Journal of Computer Vision}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2009}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{83}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{149--163}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s11263-009-0229-x}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Boosting, AdaBoost, Sequential probability ratio test, Sequential
  	decision making, WaldBoost, Interest point detectors, Machine learning}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2008</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/tracking-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/tracking-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/tracking-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/tracking.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="tracking.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="Grabner2008" class="col-sm-8">
        <!-- Title -->
        <div class="title">Training Sequential On-line Boosting Classifier for Visual Tracking</div>
        <!-- Author -->
        <div class="author">
        

        H. Grabner, <em>J. Šochman</em>, H. Bischof, and J. Matas</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In 19th International Conference on Pattern Recognition</em>, Jun 2008
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/Sochman-icpr2008.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1109/ICPR.2008.4761678"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1109/ICPR.2008.4761678" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>On-line boosting allows to adapt a trained classifier
to changing environmental conditions or to use sequentially
available training data. Yet, two important problems
in the on-line boosting training remain unsolved:
(i) classifier evaluation speed optimization and, (ii) automatic
classifier complexity estimation. In this paper
we show how the on-line boosting can be combined with
Wald’s sequential decision theory to solve both of the
problems.

The properties of the proposed on-line WaldBoost algorithm
are demonstrated on a visual tracking problem.
The complexity of the classifier is changing dynamically
depending on the difficulty of the problem. On average,
a speedup of a factor of 5-10 is achieved compared to
the non-sequential on-line boosting.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Grabner2008</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Grabner, H. and {\v S}ochman, J. and Bischof, H. and Matas, J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Training Sequential On-line Boosting Classifier for Visual Tracking}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{19th International Conference on Pattern Recognition}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2008}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICPR.2008.4761678}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2007</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/emulator-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/emulator-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/emulator-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/emulator.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="emulator.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="Sochman-accv2007" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning A Fast Emulator of a Binary Decision Process</div>
        <!-- Author -->
        <div class="author">
        

        <em>Jan Šochman</em>, and Jiřı́ Matas</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In ACCV</em>, Jun 2007
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/sochman-accv2007.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1007/978-3-540-76390-1_24"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-540-76390-1_24" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Computation time is an important performance characteristic of computer
	vision algorithms. This paper shows how existing (slow) binary-valued
	decision algorithms can be approximated by a trained WaldBoost classifier,
	which minimises the decision time while guaranteeing predefined approximation
	precision. The core idea is to take an existing algorithm as a black
	box performing some useful binary decision task and to train the
	WaldBoost classifier as its emulator.
	
	
	 Two interest point detectors, Hessian-Laplace and Kadir-Brady saliency
	detector, are emulated to demonstrate the approach. The experiments
	show similar repeatability and matching score of the original and
	emulated algorithms while achieving a 70-fold speed-up for Kadir-Brady
	detector.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Sochman-accv2007</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{{\v S}ochman, Jan and Matas, Ji{\v r}{\' \i}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning A Fast Emulator of a Binary Decision Process}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ACCV}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2007}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Yagi, Yasushi and Kang, Sing Bing and Kweon, In So and Zha, Hongbin}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{II}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{236--245}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Berlin Heidelberg}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{LNSC}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-540-76389-5}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-540-76390-1_24}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2005</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/wb-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/wb-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/wb-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/wb.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="wb.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="sochman-waldboost-cvpr05" class="col-sm-8">
        <!-- Title -->
        <div class="title">WaldBoost  - Learning for Time Constrained Sequential Detection</div>
        <!-- Author -->
        <div class="author">
        

        <em>Jan Šochman</em>, and Jiřı́ Matas</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proc. of Conference on Computer Vision and Pattern Recognition (CVPR)</em>, Jun 2005
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/sochman-waldboost-cvpr05.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1109/CVPR.2005.373"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1109/CVPR.2005.373" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sochman-waldboost-cvpr05</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{{\v S}ochman, Jan and Matas, Ji{\v r}{\' \i}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{WaldBoost  - Learning for Time Constrained Sequential Detection}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. of Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Los Alamitos, USA}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2005}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">day</span> <span class="p">=</span> <span class="s">{20--25}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{0-7695-2372-2}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE Computer Society}</span><span class="p">,</span>
  <span class="na">book_pages</span> <span class="p">=</span> <span class="s">{1219}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{150--157}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CVPR.2005.373}</span><span class="p">,</span>
  <span class="na">annote</span> <span class="p">=</span> <span class="s">{ In many computer vision classification problems, both the
    error and time characterizes the quality of a decision. We show that
    such problems can be formalized in the framework of sequential
    decision-making. If the false positive and false negative error
    rates are given, the optimal strategy in terms of the shortest
    average time to decision (number of measurements used) is the Wald's
    sequential probability ratio test (SPRT).  We built on the optimal
    SPRT test and enlarge its capabilities to problems with dependent
    measurements. We show, how the limitations of SPRT to a priori
    ordered measurements and known joint probability density functions
    can be overcome. We propose an algorithm with near optimal time -
    error rate trade-off, called WaldBoost, which integrates the
    AdaBoost algorithm for measurement selection and ordering and the
    joint probability density estimation with the optimal SPRT decision
    strategy.  The WaldBoost algorithm is tested on the face detection
    problem. The results are superior to the state-of-the-art methods in
    average evaluation time and comparable in detection rates.  }</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Adaboost, cascade, Wald's SPRT, sequential analysis, face detection}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Schmid, Cordelia and Soatto, Stefano and Tomasi, Carlo}</span><span class="p">,</span>
  <span class="na">venue</span> <span class="p">=</span> <span class="s">{San Diego, California, USA  }</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{ 2 }</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>


</div>

          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Jan  Šochman. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
